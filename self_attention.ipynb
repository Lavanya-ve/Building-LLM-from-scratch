{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50a45f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The attention weight for input 2 is: tensor([0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "#Learning simple self-attention\n",
    "\n",
    "inputs = torch.tensor([\n",
    "    [0.43, 0.15, 0.89],\n",
    "    [0.55, 0.87, 0.66],\n",
    "    [0.57, 0.85, 0.64],\n",
    "    [0.22, 0.58, 0.33],\n",
    "    [0.77, 0.25, 0.10],\n",
    "    [0.05, 0.80, 0.55]\n",
    "])\n",
    "\n",
    "#Attention weights for the second input - [0.55, 0.87, 0.66], the q,k,v here is the input embedding itself\n",
    "#Attention weights are - Q.K\n",
    "\n",
    "query_input = inputs[1]\n",
    "attention_weight_2 = torch.zeros(len(inputs))\n",
    "\n",
    "for i,x_i in enumerate(inputs):\n",
    "    attention_weight_2[i] = torch.dot(query_input, x_i)\n",
    "\n",
    "print(f\"The attention weight for input 2 is: {attention_weight_2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aad43735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The attention scores are: tensor([0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581])\n"
     ]
    }
   ],
   "source": [
    "#Moving on to attention scores = normalized attention weights whose sum is equal to 1\n",
    "attention_scores_2 = torch.softmax(attention_weight_2, dim=0)\n",
    "print(f\"The attention scores are: {attention_scores_2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54fecab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the context vector is: torch.Size([3])\n",
      "Shape of the contenxt_vector without matmul is: torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "#Let's move on to the context vector for input 2.\n",
    "#Context vector is computed as a combination of all input vectors weighted with respect to input 2\n",
    "#attention scores = softmax(Q.K), context vector = attention scores . V\n",
    "attention_scores_2.unsqueeze(0)\n",
    "context_vector_2 = attention_scores_2 @ inputs\n",
    "print(f\"Shape of the context vector is: {context_vector_2.shape}\")\n",
    "\n",
    "#This can also be done in the following way \n",
    "context_vector_2_sim = torch.zeros(query_input.shape)\n",
    "attention_scores_2.squeeze()\n",
    "\n",
    "for i,x_i in enumerate(inputs):\n",
    "    context_vector_2_sim += attention_scores_2[i]*x_i\n",
    "\n",
    "print(f\"Shape of the contenxt_vector without matmul is: {context_vector_2_sim.shape}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f54c73da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention scores are: tensor([[-0.0134, -0.1257, -0.1229, -0.0847, -0.0387, -0.1151],\n",
      "        [-0.1208, -0.1911, -0.1837, -0.1217, -0.0004, -0.1987],\n",
      "        [-0.1140, -0.1839, -0.1770, -0.1173, -0.0016, -0.1907],\n",
      "        [-0.0930, -0.1204, -0.1152, -0.0755,  0.0096, -0.1291],\n",
      "        [ 0.0394, -0.0039, -0.0051, -0.0054, -0.0244,  0.0058],\n",
      "        [-0.1613, -0.1956, -0.1869, -0.1219,  0.0216, -0.2122]],\n",
      "       grad_fn=<MmBackward0>)\n",
      "Attention scores when normalized ----> Attention weights: tensor([[0.1750, 0.1617, 0.1620, 0.1664, 0.1719, 0.1629],\n",
      "        [0.1683, 0.1601, 0.1609, 0.1682, 0.1832, 0.1593],\n",
      "        [0.1685, 0.1603, 0.1611, 0.1681, 0.1824, 0.1596],\n",
      "        [0.1659, 0.1627, 0.1633, 0.1680, 0.1784, 0.1617],\n",
      "        [0.1712, 0.1661, 0.1659, 0.1659, 0.1637, 0.1672],\n",
      "        [0.1642, 0.1603, 0.1613, 0.1689, 0.1869, 0.1584]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "The context vector is: tensor([[ 0.0274, -0.0842],\n",
      "        [ 0.0325, -0.0891],\n",
      "        [ 0.0322, -0.0888],\n",
      "        [ 0.0312, -0.0874],\n",
      "        [ 0.0251, -0.0812],\n",
      "        [ 0.0344, -0.0908]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "dim_in = inputs.shape[1]\n",
    "dim_out = 2\n",
    "\n",
    "#Compute self-attention with weights \n",
    "class SelfAttention_V1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.W_query = nn.Linear(dim_in, dim_out, bias=False)\n",
    "        self.W_key = nn.Linear(dim_in, dim_out, bias=False)\n",
    "        self.W_value = nn.Linear(dim_in, dim_out, bias=False)\n",
    "\n",
    "    def forward(self, input):\n",
    "        query = self.W_query(input)\n",
    "        key = self.W_key(input)\n",
    "        value = self.W_value(input)\n",
    "\n",
    "        d_k = key.shape[1]\n",
    "\n",
    "        attention_scores = query @ key.T\n",
    "        print(f\"Attention scores are: {attention_scores}\")\n",
    "        attention_weights = torch.softmax(attention_scores/d_k**0.5, dim=-1)\n",
    "        print(f\"Attention scores when normalized ----> Attention weights: {attention_weights}\")\n",
    "        context_vector = attention_weights @ value\n",
    "\n",
    "        return context_vector\n",
    "    \n",
    "selfattention_v1 = SelfAttention_V1()\n",
    "context_vector = selfattention_v1(inputs)\n",
    "print(f\"The context vector is: {context_vector}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a200579",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python Latest_Env",
   "language": "python",
   "name": "my_env_name"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
